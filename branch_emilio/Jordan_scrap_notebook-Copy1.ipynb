{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'sample_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "# class that defines and loads the dataset\n",
    "# Dataset is a parent!!!\n",
    "class GetDataset(Dataset):\n",
    "    \n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, dataset_name):\n",
    "        \n",
    "        # 1 == the number of classes (not including background), \n",
    "        # dataset_name is to help keep track of what the instance of the\n",
    "        # class is holding. In this case it's \"sand_dollar\"\n",
    "        self.add_class('dataset', 1, dataset_name)\n",
    "    \n",
    "        # Will need to change this when we have the \n",
    "        # real dataset\n",
    "        source = 'sample_data/'\n",
    "        \n",
    "        # Goes through all of the folder, records the basename of each file\n",
    "        # then knowing that each the filenames are the same, just concats the suffix\n",
    "        # to the basename, then appends each to their respective arrays\n",
    "        \n",
    "        # !!! Change to use glob instead of os !!!\n",
    "        for file in os.listdir(source):\n",
    "            \n",
    "            # makes it so that we only loop through once and twice (i.e. creating duplicates)\n",
    "            if(\".orig.xml\" in file):\n",
    "\n",
    "                filename = file.split(\".orig\")[0]\n",
    "                image_ids = filename\n",
    "\n",
    "                xml_path =source + filename + \".orig.xml\"\n",
    "\n",
    "                image_path = source + filename + \".orig.jpg\"\n",
    "                \n",
    "                self.add_image('dataset', image_id = image_ids, path = image_path, annotation = xml_path)        \n",
    "            \n",
    "    # extract bounding boxes from an annotation file\n",
    "    def extract_boxes(self, filename):\n",
    "        \n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        \n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(coors)\n",
    "        \n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        \n",
    "        return boxes, width, height\n",
    " \n",
    "    # load the masks for an image\n",
    "    def load_mask(self, image_id):\n",
    "        \n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        \n",
    "        # define box file location\n",
    "        path = info['annotation']\n",
    "        \n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        \n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        \n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index('sand_dollar'))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    " \n",
    "    # load an image reference\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'sand_dollar'\n",
    "\n",
    "# train set\n",
    "train_set = GetDataset()\n",
    "train_set.load_dataset(dataset_name)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    " \n",
    "# test/val set\n",
    "test_set = GetDataset()\n",
    "test_set.load_dataset(dataset_name)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a display of a image and a annotation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.random.randint(len(train_set.image_ids))\n",
    "\n",
    "image = train_set.load_image(index)\n",
    "print(image.shape)\n",
    "# load image mask\n",
    "mask, class_ids = train_set.load_mask(index)\n",
    "print(mask.shape)\n",
    "# plot image\n",
    "plt.imshow(image)\n",
    "# plot mask\n",
    "plt.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives a view of what's going on in the object we created\n",
    "def sanity_check(dataset):\n",
    "    for image_id in dataset.image_ids:\n",
    "        # load image info\n",
    "        info = dataset.image_info[image_id]\n",
    "        # display on the console\n",
    "        print(info)\n",
    "        \n",
    "#sanity_check(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides a better display of a image, and ALL of the annotations for said image\n",
    "# takes a bit of time, blame the original repo, but at least it's pretty :)\n",
    "\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "# in visualize.py, change line 28 to \"from Mask_RCNN.mrcnn import utils\" :)\n",
    "\n",
    "# define image id\n",
    "index = 5\n",
    "\n",
    "print(train_set.image_reference(index))\n",
    "\n",
    "# load the image\n",
    "image = train_set.load_image(index)\n",
    "\n",
    "# load the masks and the class ids\n",
    "mask, class_ids = train_set.load_mask(index)\n",
    "\n",
    "# extract bounding boxes from the masks\n",
    "bbox = extract_bboxes(mask)\n",
    "\n",
    "print(\"Number of annotations:\", mask.shape[2])\n",
    "# display image with masks and bounding boxes\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mask_RCNN.mrcnn.config import Config\n",
    "\n",
    "# define a configuration for the training process\n",
    "# can change the configure file, see the original\n",
    "# MaskRCNN repo for details about different hyperparameters!\n",
    "\n",
    "# Will need everyone's help figuring out the hyperparameters!\n",
    "class TrainConfig(Config):\n",
    "   \n",
    "    # define the name of the configuration\n",
    "    NAME = \"sand_dollar_config\"\n",
    "    \n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    # number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    \n",
    "    # number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = len(train_set.image_ids)\n",
    "    \n",
    "    IMAGE_MIN_DIM = 128\n",
    "    \n",
    "    IMAGE_MAX_DIM = 128\n",
    "    \n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    \n",
    "    \n",
    "training_config = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "# Change line 29 in model.py to \"from Mask_RCNN.mrcnn import utils\"\n",
    "\n",
    "training_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing training images and mask based on the details in the config file\n",
    "from Mask_RCNN.mrcnn import utils, visualize\n",
    "\n",
    "image = train_set.load_image(index)\n",
    "mask, class_ids = train_set.load_mask(index)\n",
    "original_shape = image.shape\n",
    "\n",
    "# Resize\n",
    "image, window, scale, padding, crop = utils.resize_image(image, min_dim=training_config.IMAGE_MIN_DIM, max_dim=training_config.IMAGE_MAX_DIM)\n",
    "\n",
    "mask = utils.resize_mask(mask, scale, padding)\n",
    "\n",
    "# Compute Bounding box\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id: \", train_set.image_reference(index))\n",
    "print(\"Original shape: \", original_shape)\n",
    "print(\"New shape:\", image.shape)\n",
    "\n",
    "# Display image and instances\n",
    "visualize.display_instances(image, bbox, mask, class_ids, train_set.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=training_config)\n",
    "\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('../Mask_RCNN/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=training_config.LEARNING_RATE, epochs=5, layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
