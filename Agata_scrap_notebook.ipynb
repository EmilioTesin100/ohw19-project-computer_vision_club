{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ElementTree\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing files by format\n",
    "Img = np.array(glob.glob('sample_data/*.jpg'))\n",
    "Anno = np.array(glob.glob('sample_data/*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prepare config\n",
    "config = sandDollarConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class sandDollarsDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"sandDollar\")\n",
    "\t\t# define data locations\n",
    "# \t\timages_dir = dataset_dir + '/images/'\n",
    "# \t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in Img:\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[12:-4]\n",
    "\t\t\t# skip bad images\n",
    "# \t\t\tif image_id in ['00090']:\n",
    "# \t\t\t\tcontinue\n",
    "\n",
    "# !!\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and len(dataset) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "#!!                \n",
    "\n",
    "# \t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = filename[:-4] + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=filename, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# define a configuration for the model\n",
    "class sandDollarConfig(Config):\n",
    "\t# Give the configuration a recognizable name\n",
    "\tNAME = \"sandDollars_cfg\"\n",
    "\t# Number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# Number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = 131                    #???????????????\n",
    "\n",
    "# prepare train set\n",
    "train_set = sandDollarsDataset()\n",
    "train_set.load_dataset('sandDollar', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# prepare test/val set\n",
    "test_set = sandDollarsDataset()\n",
    "test_set.load_dataset('sandDollar', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# prepare config\n",
    "config = sandDollarsConfig()\n",
    "# config.display()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
